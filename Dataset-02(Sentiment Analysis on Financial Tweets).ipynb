{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bfee20-1705-45f1-8c16-7145df923e99",
   "metadata": {},
   "source": [
    " **Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777999e8-caf4-4983-899f-c1b38562a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "from torch.optim import AdamW\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752c4ca-96da-4873-86e2-8be0e791f6ee",
   "metadata": {},
   "source": [
    " **Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de505a3-fd6b-401e-b4f7-5ead97895786",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"ðŸ–¥ï¸ Using device:\", device)\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48253c66-8a41-44a4-b196-63c1eb247151",
   "metadata": {},
   "source": [
    " **Load and Prepare Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06610c6c-eaca-4723-9571-c16192430d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\VARSHINI.M\\OneDrive\\Desktop\\7th sem\\interdisclipinary\\Datasets\\Sentiment Analysis on Financial Tweets\\tweet_sentiment.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"latin-1\", header=None)\n",
    "df.columns = [\"text\", \"sentiment\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb3f77-81d7-4813-8704-c78bd6fd131e",
   "metadata": {},
   "source": [
    "**Clean and filter sentiment values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b93e6-f5db-419a-890a-cefa976bb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"].isin([\"positive\", \"neutral\", \"negative\", \"1\", \"0\", \"-1\"])]\n",
    "sentiment_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2, \"-1\": 0, \"0\": 1, \"1\": 2}\n",
    "df[\"sentiment\"] = pd.to_numeric(df[\"sentiment\"].replace(sentiment_map), errors=\"coerce\")\n",
    "df.dropna(subset=[\"sentiment\"], inplace=True)\n",
    "df[\"sentiment\"] = df[\"sentiment\"].astype(int)\n",
    "print(\" Original Class Distribution:\")\n",
    "print(df[\"sentiment\"].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b5e94-0a30-49e9-b054-297d2491dc0f",
   "metadata": {},
   "source": [
    "**Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a2612-d8f7-46f8-87b7-6f9a41941f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+|#\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83641c5e-cbe2-435b-92bb-a592e42a217a",
   "metadata": {},
   "source": [
    "**Handle Class Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db84db8-b0a6-4bcb-95d5-7fb01882382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df[\"sentiment\"].value_counts()\n",
    "if len(counts) > 1 and counts.max() / counts.min() > 1.5:\n",
    "    print(\"âš–ï¸ Oversampling minority classes...\")\n",
    "    df_neg = df[df[\"sentiment\"] == 0]\n",
    "    df_neu = df[df[\"sentiment\"] == 1]\n",
    "    df_pos = df[df[\"sentiment\"] == 2]\n",
    "    max_size = max(len(df_neg), len(df_neu), len(df_pos))\n",
    "\n",
    "    df_neg_over = resample(df_neg, replace=True, n_samples=max_size, random_state=42)\n",
    "    df_neu_over = resample(df_neu, replace=True, n_samples=max_size, random_state=42)\n",
    "    df_pos_over = resample(df_pos, replace=True, n_samples=max_size, random_state=42)\n",
    "\n",
    "    df = pd.concat([df_neg_over, df_neu_over, df_pos_over])\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    print(\" Class distribution is already balanced or uniform.\")\n",
    "\n",
    "print(\" Final Class Distribution:\")\n",
    "print(df[\"sentiment\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505dff8c-ef10-4864-8579-2616f4881982",
   "metadata": {},
   "source": [
    "**Split Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95329b1a-6da4-4ec8-a9b9-3451a2fcec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df[\"clean_text\"], df[\"sentiment\"], test_size=0.3, stratify=df[\"sentiment\"], random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“š Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3503eb-3976-42b1-b4f0-49d6ab4cadf1",
   "metadata": {},
   "source": [
    "**Tokenization using FinBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ccbd1-caa6-4e56-9df1-e3f495824094",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "def encode_texts(texts, max_len=128):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_enc = encode_texts(X_train)\n",
    "val_enc = encode_texts(X_val)\n",
    "test_enc = encode_texts(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0065b2b5-3c7d-4bd8-80ee-b199dcc92b76",
   "metadata": {},
   "source": [
    "**Dataset Wrapper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4a7e4-1c1d-4e5b-92a7-8f01232e14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"labels\": torch.tensor(self.labels.iloc[idx])\n",
    "        }\n",
    "\n",
    "train_ds = SentimentDataset(train_enc, y_train)\n",
    "val_ds = SentimentDataset(val_enc, y_val)\n",
    "test_ds = SentimentDataset(test_enc, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9507a47-0e51-4aad-be91-80bfe10d0ffa",
   "metadata": {},
   "source": [
    "**FinBERT + LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cf68e-4fed-4947-bcc4-480378b59328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinBERT_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes=3):\n",
    "        super(FinBERT_LSTM, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"ProsusAI/finbert\")\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.bert.config.hidden_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():  # Freeze FinBERT\n",
    "            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        lstm_out, _ = self.lstm(bert_output.last_hidden_state)\n",
    "        pooled = torch.mean(lstm_out, dim=1)\n",
    "        out = self.dropout(pooled)\n",
    "        return self.fc(out)\n",
    "\n",
    "model = FinBERT_LSTM().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70697833-ef66-4144-a435-c1c0fffc1914",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a507c8-ba61-46a9-b55a-2a76c831b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            ids = batch[\"input_ids\"].to(device)\n",
    "            mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(ids, mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total, total_loss / len(loader)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        optimizer.zero_grad()\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(ids, mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    val_acc, val_loss = evaluate(val_loader)\n",
    "    test_acc, test_loss = evaluate(test_loader)\n",
    "\n",
    "    print(f\"\\n Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"Train â†’ Acc: {train_acc*100:.2f}% | Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val   â†’ Acc: {val_acc*100:.2f}% | Loss: {val_loss:.4f}\")\n",
    "    print(f\"Test  â†’ Acc: {test_acc*100:.2f}% | Loss: {test_loss:.4f}\")\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf5014-ea60-49dd-8f78-63c47df5802b",
   "metadata": {},
   "source": [
    "**Plot Accuracy and Loss Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc8ce0-c8be-455a-b5f7-8886585d3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, history[\"train_acc\"], marker='o', label=\"Train Accuracy\")\n",
    "plt.plot(epochs_range, history[\"val_acc\"], marker='o', label=\"Validation Accuracy\")\n",
    "plt.plot(epochs_range, history[\"test_acc\"], marker='o', label=\"Test Accuracy\")\n",
    "plt.title(\"ðŸ“ˆ Model Accuracy (Train / Val / Test)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history[\"train_loss\"], marker='o', label=\"Train Loss\")\n",
    "plt.plot(epochs_range, history[\"val_loss\"], marker='o', label=\"Validation Loss\")\n",
    "plt.plot(epochs_range, history[\"test_loss\"], marker='o', label=\"Test Loss\")\n",
    "plt.title(\"ðŸ“‰ Model Loss (Train / Val / Test)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942e619-d1f3-470a-9299-724d04400247",
   "metadata": {},
   "source": [
    "**Save and Reload Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d8a512-ce52-4ab3-93f6-527280b37d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"finbert_lstm_model.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\" Model saved as {MODEL_PATH}\\n\")\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99703a-9025-420e-9905-cde6de2a24bc",
   "metadata": {},
   "source": [
    "**Prediction Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692b6db-12ae-4a27-9bb1-0d8668e7115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    cleaned = clean_text(sentence)\n",
    "    encoded = tokenizer(cleaned, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attn_mask = encoded[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attn_mask)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return label_map[pred]\n",
    "\n",
    "# Example Predictions (2-line sentences)\n",
    "print(\"\\nðŸ’¬ Example Predictions:\")\n",
    "examples = [\n",
    "    \"The company reported record profits this quarter! Sales exceeded expectations across all regions.\",\n",
    "    \"The stock market is unstable due to new regulations. Many investors are pulling back from risky assets.\",\n",
    "    \"Investors are unsure about the future of this firm. Recent management changes raised serious concerns.\",\n",
    "    \"The merger between the two banks was well received by analysts. Shares rose sharply after the announcement.\",\n",
    "    \"Weak consumer demand continues to hurt quarterly earnings. The firm announced potential layoffs next month.\",\n",
    "    \"The governmentâ€™s new tax incentives boosted corporate confidence. Economic growth projections were revised upward.\",\n",
    "    \"Rising inflation has reduced purchasing power. Retail stocks dropped amid declining customer sentiment.\",\n",
    "    \"The companyâ€™s innovative AI product attracted major investors. Market experts predict strong revenue growth.\"\n",
    "]\n",
    "for s in examples:\n",
    "    print(f\"{s} â†’ {predict_sentiment(s)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb134b5-cf82-4015-ba2e-fcd877ecebd9",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a8911-7a42-48e0-9d69-f80acdfd9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_all(model, datasets, true_labels, set_names, normalize=False):\n",
    "    model.eval()\n",
    "    num_sets = len(datasets)\n",
    "    fig, axes = plt.subplots(1, num_sets, figsize=(6*num_sets, 5))\n",
    "    if num_sets == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (dataset, y_true, name) in enumerate(zip(datasets, true_labels, set_names)):\n",
    "        loader = DataLoader(dataset, batch_size=32)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                ids = batch[\"input_ids\"].to(device)\n",
    "                mask = batch[\"attention_mask\"].to(device)\n",
    "                outputs = model(ids, mask)\n",
    "                preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        cm = confusion_matrix(y_true, preds, normalize=\"true\" if normalize else None)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "        disp.plot(ax=axes[i], cmap=\"Blues\", values_format=\".2f\" if normalize else \"d\", colorbar=False)\n",
    "        axes[i].set_title(f\"{name} Confusion Matrix\")\n",
    "\n",
    "    plt.suptitle(\"ðŸ“‰ Confusion Matrices - FinBERT + LSTM\", fontsize=14, y=1.03)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix_all(\n",
    "    model,\n",
    "    datasets=[train_ds, val_ds, test_ds],\n",
    "    true_labels=[y_train, y_val, y_test],\n",
    "    set_names=[\"Train\", \"Validation\", \"Test\"],\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27764187-ffb7-400a-98d7-bf7b3d8def3f",
   "metadata": {},
   "source": [
    "**Overall Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c86b1-b80a-4b92-b2d6-e7767582afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_confusion_matrix(model, datasets, true_labels, normalize=False):\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    for dataset, y_true in zip(datasets, true_labels):\n",
    "        loader = DataLoader(dataset, batch_size=32)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                ids = batch[\"input_ids\"].to(device)\n",
    "                mask = batch[\"attention_mask\"].to(device)\n",
    "                outputs = model(ids, mask)\n",
    "                preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        all_preds.extend(preds)\n",
    "        all_true.extend(y_true)\n",
    "\n",
    "    cm = confusion_matrix(all_true, all_preds, normalize=\"true\" if normalize else None)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\" if normalize else \"d\")\n",
    "    plt.title(\"ðŸ“‰ Overall Confusion Matrix - FinBERT + LSTM\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nðŸ“Š Classification Report (Overall):\")\n",
    "    print(classification_report(all_true, all_preds, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n",
    "\n",
    "plot_overall_confusion_matrix(\n",
    "    model,\n",
    "    datasets=[train_ds, val_ds, test_ds],\n",
    "    true_labels=[y_train, y_val, y_test],\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e239d6-a3e2-432f-bb5a-3093e9ce4ffc",
   "metadata": {},
   "source": [
    " **LOAD SAVED MODEL & PREDICT IN REAL-TIME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14ba93-97b0-4717-9dac-c8c08a720d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"finbert_lstm_balanced_model.pth\"\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Loaded model from: {MODEL_PATH}\")\n",
    "\n",
    "#  Define Prediction Function\n",
    "def predict_sentiment(sentence):\n",
    "    model.eval()\n",
    "    cleaned = clean_text(sentence)\n",
    "    encoded = tokenizer(cleaned, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attn_mask = encoded['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attn_mask)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    sentiment_val = idx_to_sentiment[pred]\n",
    "    return f\"{idx_to_label[pred]} ({sentiment_val})\"\n",
    "\n",
    "# Example Predictions\n",
    "print(\"\\nðŸ’¬ Example Predictions:\")\n",
    "examples = [\n",
    "    \"The company reported record profits this quarter! Sales exceeded expectations across all regions.\",\n",
    "    \"The stock market is unstable due to new regulations. Many investors are pulling back from risky assets.\",\n",
    "    \"Investors are unsure about the future of this firm. Its recent management changes raised serious concerns.\",\n",
    "    \"The merger between the two banks was well received by analysts. Shares rose sharply after the announcement.\",\n",
    "    \"Weak consumer demand continues to hurt quarterly earnings. The firm announced potential layoffs next month.\",\n",
    "    \"The governmentâ€™s new tax incentives boosted corporate confidence. Economic growth projections were revised upward.\",\n",
    "    \"Rising inflation has reduced purchasing power. Retail stocks dropped amid declining customer sentiment.\",\n",
    "    \"The companyâ€™s innovative AI product attracted major investors. Market experts predict strong revenue growth.\"\n",
    "]\n",
    "for s in examples:\n",
    "    print(f\"{s} â†’ {predict_sentiment(s)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724add9-92c0-4532-8375-1cbb65b5181a",
   "metadata": {},
   "source": [
    "# **Modelwithout pre trained model(Finbert)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447314cc-dd9e-4b94-8c91-6e6b7d11e001",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e366cec-3efc-461c-ab70-c571fe058cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de14159-7e20-408f-b96b-d53397bd8850",
   "metadata": {},
   "source": [
    "**Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a5695-2629-4dd8-b851-038eb31a2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05232a0b-7682-47f1-95af-c9c215f6594a",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f179771-d6a9-4da7-935b-8d5bce57269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/tweet_sentiment.csv\"  #\n",
    "    df = pd.read_csv(file_path, encoding='latin-1', header=None)\n",
    "    df.columns = ['text', 'sentiment']\n",
    "\n",
    "    df = df[df['sentiment'].isin(['positive', 'negative', 'neutral', '1', '0', '-1'])]\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty after filtering. Check the CSV format.\")\n",
    "\n",
    "    sentiment_map = {'negative': 0, 'neutral': 1, 'positive': 2, '-1': 0, '0': 1, '1': 2}\n",
    "    df['sentiment'] = pd.to_numeric(df['sentiment'].replace(sentiment_map), errors='coerce')\n",
    "    df = df.dropna(subset=['sentiment'])\n",
    "    df['sentiment'] = df['sentiment'].astype(int)\n",
    "\n",
    "    print(\"Original Class Distribution:\")\n",
    "    print(df['sentiment'].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48361602-1245-41fc-b40f-404740042cfe",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca143-c605-440f-8534-6b7ad0fc9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    " stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "        text = re.sub(r\"@\\w+|#\", \"\", text)\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    df['clean_text'] = df['text'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b52cc-3d3d-4b0a-862d-2cce8dd68f7e",
   "metadata": {},
   "source": [
    "**Handle Class Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47808ee4-5f09-460f-ad9c-94876e2d38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['sentiment'].value_counts()\n",
    "    if counts.max() / counts.min() > 1.5:\n",
    "        print(\"Oversampling minority classes...\")\n",
    "        df_neg = df[df['sentiment'] == 0]\n",
    "        df_neu = df[df['sentiment'] == 1]\n",
    "        df_pos = df[df['sentiment'] == 2]\n",
    "        max_size = max(len(df_neg), len(df_neu), len(df_pos))\n",
    "        df_neg_over = resample(df_neg, replace=True, n_samples=max_size, random_state=42)\n",
    "        df_neu_over = resample(df_neu, replace=True, n_samples=max_size, random_state=42)\n",
    "        df_pos_over = resample(df_pos, replace=True, n_samples=max_size, random_state=42)\n",
    "        df = pd.concat([df_neg_over, df_neu_over, df_pos_over]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(\"Final Class Distribution:\")\n",
    "    print(df['sentiment'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8df2da-0dfa-466d-be21-3d1fd59c47a9",
   "metadata": {},
   "source": [
    "**Split Data (70 : 15 : 15)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2abe4-beac-4ff1-8d1f-189b77a1642f",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        df['clean_text'], df['sentiment'], test_size=0.3,\n",
    "        stratify=df['sentiment'], random_state=42\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5,\n",
    "        stratify=y_temp, random_state=42\n",
    "    )\n",
    "    print(f\"Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db88607-2d79-41e3-9b66-5067945f95f2",
   "metadata": {},
   "source": [
    "**Tokenization + Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237764f7-95d0-4a71-a51d-ffc02ea4375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "        return text.split()\n",
    "\n",
    "    vocab = Counter()\n",
    "    for txt in X_train:\n",
    "        vocab.update(tokenize(txt))\n",
    "    vocab = {word: idx + 2 for idx, (word, _) in enumerate(vocab.most_common())}\n",
    "    vocab[\"<PAD>\"] = 0\n",
    "    vocab[\"<UNK>\"] = 1\n",
    "\n",
    "    def encode(text, max_len=50):\n",
    "        tokens = tokenize(text)\n",
    "        ids = [vocab.get(t, vocab[\"<UNK>\"]) for t in tokens]\n",
    "        if len(ids) < max_len:\n",
    "            ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[:max_len]\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "    class TextDataset(Dataset):\n",
    "        def __init__(self, texts, labels):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "        def __getitem__(self, idx):\n",
    "            x = encode(self.texts.iloc[idx])\n",
    "            y = torch.tensor(self.labels.iloc[idx])\n",
    "            return x, y\n",
    "\n",
    "    train_ds = TextDataset(X_train, y_train)\n",
    "    val_ds = TextDataset(X_val, y_val)\n",
    "    test_ds = TextDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32)\n",
    "    test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120dee9b-036f-49d0-b91f-caa7ee619690",
   "metadata": {},
   "source": [
    "**LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be40a10-964f-4470-a05f-3e97a1baad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "        def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=3):\n",
    "            super(SimpleLSTM, self).__init__()\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "            self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "            self.dropout = nn.Dropout(0.3)\n",
    "            self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            emb = self.embedding(x)\n",
    "            lstm_out, _ = self.lstm(emb)\n",
    "            pooled = torch.mean(lstm_out, dim=1)\n",
    "            out = self.dropout(pooled)\n",
    "            return self.fc(out)\n",
    "\n",
    "    model = SimpleLSTM(len(vocab), embed_dim=128, hidden_dim=128, num_classes=3).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64c43c-8885-41b9-81fd-d76393b0af23",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9448222-4ac0-4015-afcf-3dec1f7f30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    " def evaluate(loader):\n",
    "        model.eval()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                total_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        return correct / total, total_loss / len(loader)\n",
    "\n",
    "    EPOCHS = 5\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "        train_acc = correct / total\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        val_acc, val_loss = evaluate(val_loader)\n",
    "        test_acc, test_loss = evaluate(test_loader)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        print(f\"Train â†’ Acc: {train_acc*100:.2f}% | Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val   â†’ Acc: {val_acc*100:.2f}% | Loss: {val_loss:.4f}\")\n",
    "        print(f\"Test  â†’ Acc: {test_acc*100:.2f}% | Loss: {test_loss:.4f}\")\n",
    "        print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ff0f7-f4c8-4a87-9c78-38d007702018",
   "metadata": {},
   "source": [
    "**Plot Accuracy and Loss Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a1181-e3d1-4588-8506-c4f4309155eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, history[\"train_acc\"], marker='o', label=\"Train Accuracy\")\n",
    "plt.plot(epochs_range, history[\"val_acc\"], marker='o', label=\"Validation Accuracy\")\n",
    "plt.plot(epochs_range, history[\"test_acc\"], marker='o', label=\"Test Accuracy\")\n",
    "plt.title(\"ðŸ“ˆ Model Accuracy (Train / Val / Test)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history[\"train_loss\"], marker='o', label=\"Train Loss\")\n",
    "plt.plot(epochs_range, history[\"val_loss\"], marker='o', label=\"Validation Loss\")\n",
    "plt.plot(epochs_range, history[\"test_loss\"], marker='o', label=\"Test Loss\")\n",
    "plt.title(\"ðŸ“‰ Model Loss (Train / Val / Test)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fbe595-ef18-4ae4-bd26-4a78b2475686",
   "metadata": {},
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ccdfb-2a44-419f-a824-5b1a9a74b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_all(model, datasets, true_labels, set_names, normalize=False):\n",
    "    model.eval()\n",
    "    num_sets = len(datasets)\n",
    "    fig, axes = plt.subplots(1, num_sets, figsize=(6*num_sets, 5))\n",
    "    if num_sets == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (dataset, y_true, name) in enumerate(zip(datasets, true_labels, set_names)):\n",
    "        loader = DataLoader(dataset, batch_size=32)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                ids = batch[\"input_ids\"].to(device)\n",
    "                mask = batch[\"attention_mask\"].to(device)\n",
    "                outputs = model(ids, mask)\n",
    "                preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        cm = confusion_matrix(y_true, preds, normalize=\"true\" if normalize else None)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "        disp.plot(ax=axes[i], cmap=\"Blues\", values_format=\".2f\" if normalize else \"d\", colorbar=False)\n",
    "        axes[i].set_title(f\"{name} Confusion Matrix\")\n",
    "\n",
    "    plt.suptitle(\"ðŸ“‰ Confusion Matrices - FinBERT + LSTM\", fontsize=14, y=1.03)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix_all(\n",
    "    model,\n",
    "    datasets=[train_ds, val_ds, test_ds],\n",
    "    true_labels=[y_train, y_val, y_test],\n",
    "    set_names=[\"Train\", \"Validation\", \"Test\"],\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11acaf58-66e1-412a-81d3-c34fc41e8f52",
   "metadata": {},
   "source": [
    "**Overall Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91146f-5624-4dbe-be95-78263b4eeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overall_confusion_matrix(model, datasets, true_labels, normalize=False):\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    for dataset, y_true in zip(datasets, true_labels):\n",
    "        loader = DataLoader(dataset, batch_size=32)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                ids = batch[\"input_ids\"].to(device)\n",
    "                mask = batch[\"attention_mask\"].to(device)\n",
    "                outputs = model(ids, mask)\n",
    "                preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        all_preds.extend(preds)\n",
    "        all_true.extend(y_true)\n",
    "\n",
    "    cm = confusion_matrix(all_true, all_preds, normalize=\"true\" if normalize else None)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\" if normalize else \"d\")\n",
    "    plt.title(\"ðŸ“‰ Overall Confusion Matrix - FinBERT + LSTM\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nðŸ“Š Classification Report (Overall):\")\n",
    "    print(classification_report(all_true, all_preds, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n",
    "\n",
    "plot_overall_confusion_matrix(\n",
    "    model,\n",
    "    datasets=[train_ds, val_ds, test_ds],\n",
    "    true_labels=[y_train, y_val, y_test],\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc63e87-c80b-486f-ac36-6046d7c833e5",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0a08f-523c-44ac-966a-4e143417c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"lstm_sentiment_model.pth\")\n",
    "    print(\"Model saved as lstm_sentiment_model.pth\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318a1bb-d09d-4ab4-8b50-b54bee599d6e",
   "metadata": {},
   "source": [
    "**Load Model and Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ce9e1-a49b-4991-9e28-15b3268743df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    cleaned = clean_text(sentence)\n",
    "    encoded = tokenizer(cleaned, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attn_mask = encoded[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attn_mask)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return label_map[pred]\n",
    "\n",
    "# Example Predictions (2-line sentences)\n",
    "print(\"\\nðŸ’¬ Example Predictions:\")\n",
    "examples = [\n",
    "    \"The company reported record profits this quarter! Sales exceeded expectations across all regions.\",\n",
    "    \"The stock market is unstable due to new regulations. Many investors are pulling back from risky assets.\",\n",
    "    \"Investors are unsure about the future of this firm. Recent management changes raised serious concerns.\",\n",
    "    \"The merger between the two banks was well received by analysts. Shares rose sharply after the announcement.\",\n",
    "    \"Weak consumer demand continues to hurt quarterly earnings. The firm announced potential layoffs next month.\",\n",
    "    \"The governmentâ€™s new tax incentives boosted corporate confidence. Economic growth projections were revised upward.\",\n",
    "    \"Rising inflation has reduced purchasing power. Retail stocks dropped amid declining customer sentiment.\",\n",
    "    \"The companyâ€™s innovative AI product attracted major investors. Market experts predict strong revenue growth.\"\n",
    "]\n",
    "for s in examples:\n",
    "    print(f\"{s} â†’ {predict_sentiment(s)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893ef54-6bba-4af7-b86a-b9e4bedde7e5",
   "metadata": {},
   "source": [
    "**Load the trained model with Real-time Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ec015-2690-40bd-b4c4-9c8cada99286",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"finbert_lstm_balanced_model.pth\"\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Loaded model from: {MODEL_PATH}\")\n",
    "\n",
    "#  Define Prediction Function\n",
    "def predict_sentiment(sentence):\n",
    "    model.eval()\n",
    "    cleaned = clean_text(sentence)\n",
    "    encoded = tokenizer(cleaned, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attn_mask = encoded['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attn_mask)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    sentiment_val = idx_to_sentiment[pred]\n",
    "    return f\"{idx_to_label[pred]} ({sentiment_val})\"\n",
    "\n",
    "# Example Predictions\n",
    "print(\"\\nðŸ’¬ Example Predictions:\")\n",
    "examples = [\n",
    "    \"The company reported record profits this quarter! Sales exceeded expectations across all regions.\",\n",
    "    \"The stock market is unstable due to new regulations. Many investors are pulling back from risky assets.\",\n",
    "    \"Investors are unsure about the future of this firm. Its recent management changes raised serious concerns.\",\n",
    "    \"The merger between the two banks was well received by analysts. Shares rose sharply after the announcement.\",\n",
    "    \"Weak consumer demand continues to hurt quarterly earnings. The firm announced potential layoffs next month.\",\n",
    "    \"The governmentâ€™s new tax incentives boosted corporate confidence. Economic growth projections were revised upward.\",\n",
    "    \"Rising inflation has reduced purchasing power. Retail stocks dropped amid declining customer sentiment.\",\n",
    "    \"The companyâ€™s innovative AI product attracted major investors. Market experts predict strong revenue growth.\"\n",
    "]\n",
    "for s in examples:\n",
    "    print(f\"{s} â†’ {predict_sentiment(s)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
